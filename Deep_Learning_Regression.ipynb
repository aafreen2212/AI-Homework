{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1NFGY9thpf9VJb7GPn+XX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aafreen2212/AI-Homework/blob/master/Deep_Learning_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7LSCCuqshNd",
        "outputId": "39cb099d-0c71-4d09-8a37-73bc583f1864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen\n",
        "resp = urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip')\n",
        "zipfile = ZipFile(BytesIO(resp.read()))\n",
        "zipfile.namelist()\n",
        "# ['bbc.classes', 'bbc.docs', 'bbc.mtx', 'bbc.terms']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Readme.txt', 'day.csv', 'hour.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-A2EdHXy43u"
      },
      "source": [
        "In this file, a regression problem is solved using deep learning appraoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0DCx30tjt5"
      },
      "source": [
        "new_files = zipfile.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNZrWANHtmeJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "day = pd.read_csv('/content/day.csv')\n",
        "hour = pd.read_csv('/content/hour.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKDwt6zKuHUG",
        "outputId": "967fcbe0-7088-40f3-e0c2-695d0790b487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "day.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.344167</td>\n",
              "      <td>0.363625</td>\n",
              "      <td>0.805833</td>\n",
              "      <td>0.160446</td>\n",
              "      <td>331</td>\n",
              "      <td>654</td>\n",
              "      <td>985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-02</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.363478</td>\n",
              "      <td>0.353739</td>\n",
              "      <td>0.696087</td>\n",
              "      <td>0.248539</td>\n",
              "      <td>131</td>\n",
              "      <td>670</td>\n",
              "      <td>801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.189405</td>\n",
              "      <td>0.437273</td>\n",
              "      <td>0.248309</td>\n",
              "      <td>120</td>\n",
              "      <td>1229</td>\n",
              "      <td>1349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-04</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.212122</td>\n",
              "      <td>0.590435</td>\n",
              "      <td>0.160296</td>\n",
              "      <td>108</td>\n",
              "      <td>1454</td>\n",
              "      <td>1562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.226957</td>\n",
              "      <td>0.229270</td>\n",
              "      <td>0.436957</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>82</td>\n",
              "      <td>1518</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered   cnt\n",
              "0        1  2011-01-01       1   0  ...   0.160446     331         654   985\n",
              "1        2  2011-01-02       1   0  ...   0.248539     131         670   801\n",
              "2        3  2011-01-03       1   0  ...   0.248309     120        1229  1349\n",
              "3        4  2011-01-04       1   0  ...   0.160296     108        1454  1562\n",
              "4        5  2011-01-05       1   0  ...   0.186900      82        1518  1600\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc1IXoauuJrS",
        "outputId": "5b436506-7bc4-4b9d-93fa-c3b6c9710e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "hour.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd-NtHm5vTLj",
        "outputId": "faac9256-7fe9-4d8f-aa29-4e16ca42e308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "hour.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "instant       0\n",
              "dteday        0\n",
              "season        0\n",
              "yr            0\n",
              "mnth          0\n",
              "hr            0\n",
              "holiday       0\n",
              "weekday       0\n",
              "workingday    0\n",
              "weathersit    0\n",
              "temp          0\n",
              "atemp         0\n",
              "hum           0\n",
              "windspeed     0\n",
              "casual        0\n",
              "registered    0\n",
              "cnt           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgl5IWaYvX3K"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT0-ekJuEBIC"
      },
      "source": [
        "data = hour.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGVEzFSxFl6u",
        "outputId": "b5d2fa50-54d7-4947-e639-cef634206b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "instant         int64\n",
              "dteday         object\n",
              "season          int64\n",
              "yr              int64\n",
              "mnth            int64\n",
              "hr              int64\n",
              "holiday         int64\n",
              "weekday         int64\n",
              "workingday      int64\n",
              "weathersit      int64\n",
              "temp          float64\n",
              "atemp         float64\n",
              "hum           float64\n",
              "windspeed     float64\n",
              "casual          int64\n",
              "registered      int64\n",
              "cnt             int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ1FavDEFtbl",
        "outputId": "ae120f6f-d674-4ebb-af59-0487ffcb1472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHHa4M4CEEC1",
        "outputId": "a4dbf7d4-30f2-47bd-8ab9-1937d30e62dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Define x and y\n",
        "X = data.drop(['instant', 'dteday', 'cnt'], axis=1)\n",
        "y = data['cnt']\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   season  yr  mnth  hr  holiday  ...   atemp   hum  windspeed  casual  registered\n",
              "0       1   0     1   0        0  ...  0.2879  0.81        0.0       3          13\n",
              "1       1   0     1   1        0  ...  0.2727  0.80        0.0       8          32\n",
              "2       1   0     1   2        0  ...  0.2727  0.80        0.0       5          27\n",
              "3       1   0     1   3        0  ...  0.2879  0.75        0.0       3          10\n",
              "4       1   0     1   4        0  ...  0.2879  0.75        0.0       0           1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qod8yteiEJ3-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1gtXMLJaiJ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(x_train)\n",
        "X_test = sc.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KZTIB7uJmXb",
        "outputId": "e8250e2b-8d4b-48e7-a4d4-3770705ea299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13903, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFpClSAEEUub"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBp3oYxxEYT6"
      },
      "source": [
        "# Initialising the ANN\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "#relu activation function is used t ReLU for short is a piecewise linear function \n",
        "#that will output the input directly if it is positive, otherwise, it will output zero. \n",
        "#It has become the default activation function for many \n",
        "#types of neural networks because a model that uses it is easier to train and often achieves better performance.\n",
        "model.add(Dense(30, activation = 'relu', input_dim = 14))\n",
        "#input_dim is the no. of columns\n",
        "# Adding the second hidden layer\n",
        "#higher the hidden unit, higher is the accuracy of the model. \n",
        "#However, hidden units should not be too big as it would increase the model complexity\n",
        "model.add(Dense(units = 125, activation = 'relu'))\n",
        "\n",
        "# Adding the third hidden layer\n",
        "model.add(Dense(units = 200, activation = 'relu'))\n",
        "#Regularization parameter: Dropout\n",
        "#the outputs of a layer under dropout are randomly subsampled, \n",
        "#it has the effect of reducing the capacity or thinning the network during training. \n",
        "#As such, a wider network, e.g. more nodes, may be required when using dropout.\n",
        "model.add(Dropout(0.25))\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04m4R8zrJzYP"
      },
      "source": [
        "model.compile(optimizer = 'adam',loss = 'mean_absolute_error', metrics = ['mean_absolute_error'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWz2rCQYL0Ua"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.{epoch:02d}-{mean_absolute_error:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='mean_absolute_error', verbose=1, save_best_only=True, mode='min')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdVTeNYyEki8",
        "outputId": "0cce9da9-2e6e-4a14-8a90-d50b8e482567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 100, callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "430/435 [============================>.] - ETA: 0s - loss: 16.9743 - mean_absolute_error: 16.9743\n",
            "Epoch 00001: mean_absolute_error improved from inf to 16.91179, saving model to weights.01-16.91.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 16.9118 - mean_absolute_error: 16.9118\n",
            "Epoch 2/100\n",
            "416/435 [===========================>..] - ETA: 0s - loss: 10.0662 - mean_absolute_error: 10.0662\n",
            "Epoch 00002: mean_absolute_error improved from 16.91179 to 10.05709, saving model to weights.02-10.06.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 10.0571 - mean_absolute_error: 10.0571\n",
            "Epoch 3/100\n",
            "420/435 [===========================>..] - ETA: 0s - loss: 10.1746 - mean_absolute_error: 10.1746\n",
            "Epoch 00003: mean_absolute_error did not improve from 10.05709\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 10.1654 - mean_absolute_error: 10.1654\n",
            "Epoch 4/100\n",
            "421/435 [============================>.] - ETA: 0s - loss: 10.0304 - mean_absolute_error: 10.0304\n",
            "Epoch 00004: mean_absolute_error improved from 10.05709 to 10.04696, saving model to weights.04-10.05.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 10.0470 - mean_absolute_error: 10.0470\n",
            "Epoch 5/100\n",
            "413/435 [===========================>..] - ETA: 0s - loss: 9.8125 - mean_absolute_error: 9.8125\n",
            "Epoch 00005: mean_absolute_error improved from 10.04696 to 9.77495, saving model to weights.05-9.77.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7750 - mean_absolute_error: 9.7750\n",
            "Epoch 6/100\n",
            "423/435 [============================>.] - ETA: 0s - loss: 9.9837 - mean_absolute_error: 9.9837  \n",
            "Epoch 00006: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.9822 - mean_absolute_error: 9.9822\n",
            "Epoch 7/100\n",
            "418/435 [===========================>..] - ETA: 0s - loss: 10.0289 - mean_absolute_error: 10.0289\n",
            "Epoch 00007: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.9568 - mean_absolute_error: 9.9568\n",
            "Epoch 8/100\n",
            "408/435 [===========================>..] - ETA: 0s - loss: 9.8532 - mean_absolute_error: 9.8532\n",
            "Epoch 00008: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8464 - mean_absolute_error: 9.8464\n",
            "Epoch 9/100\n",
            "420/435 [===========================>..] - ETA: 0s - loss: 9.9132 - mean_absolute_error: 9.9132\n",
            "Epoch 00009: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8852 - mean_absolute_error: 9.8852\n",
            "Epoch 10/100\n",
            "430/435 [============================>.] - ETA: 0s - loss: 9.8045 - mean_absolute_error: 9.8045\n",
            "Epoch 00010: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8170 - mean_absolute_error: 9.8170\n",
            "Epoch 11/100\n",
            "422/435 [============================>.] - ETA: 0s - loss: 9.7970 - mean_absolute_error: 9.7970\n",
            "Epoch 00011: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8380 - mean_absolute_error: 9.8380\n",
            "Epoch 12/100\n",
            "433/435 [============================>.] - ETA: 0s - loss: 9.8946 - mean_absolute_error: 9.8946\n",
            "Epoch 00012: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8833 - mean_absolute_error: 9.8833\n",
            "Epoch 13/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.8661 - mean_absolute_error: 9.8661\n",
            "Epoch 00013: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8407 - mean_absolute_error: 9.8407\n",
            "Epoch 14/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.8440 - mean_absolute_error: 9.8440\n",
            "Epoch 00014: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8112 - mean_absolute_error: 9.8112\n",
            "Epoch 15/100\n",
            "429/435 [============================>.] - ETA: 0s - loss: 9.8140 - mean_absolute_error: 9.8140\n",
            "Epoch 00015: mean_absolute_error did not improve from 9.77495\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.8201 - mean_absolute_error: 9.8201\n",
            "Epoch 16/100\n",
            "418/435 [===========================>..] - ETA: 0s - loss: 9.7033 - mean_absolute_error: 9.7033\n",
            "Epoch 00016: mean_absolute_error improved from 9.77495 to 9.73861, saving model to weights.16-9.74.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7386 - mean_absolute_error: 9.7386\n",
            "Epoch 17/100\n",
            "433/435 [============================>.] - ETA: 0s - loss: 9.7056 - mean_absolute_error: 9.7056\n",
            "Epoch 00017: mean_absolute_error improved from 9.73861 to 9.72089, saving model to weights.17-9.72.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7209 - mean_absolute_error: 9.7209\n",
            "Epoch 18/100\n",
            "435/435 [==============================] - ETA: 0s - loss: 9.7671 - mean_absolute_error: 9.7671\n",
            "Epoch 00018: mean_absolute_error did not improve from 9.72089\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7671 - mean_absolute_error: 9.7671\n",
            "Epoch 19/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.5840 - mean_absolute_error: 9.5840\n",
            "Epoch 00019: mean_absolute_error improved from 9.72089 to 9.58843, saving model to weights.19-9.59.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.5884 - mean_absolute_error: 9.5884\n",
            "Epoch 20/100\n",
            "422/435 [============================>.] - ETA: 0s - loss: 9.7610 - mean_absolute_error: 9.7610\n",
            "Epoch 00020: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7538 - mean_absolute_error: 9.7538\n",
            "Epoch 21/100\n",
            "428/435 [============================>.] - ETA: 0s - loss: 9.6184 - mean_absolute_error: 9.6184\n",
            "Epoch 00021: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.6027 - mean_absolute_error: 9.6027\n",
            "Epoch 22/100\n",
            "430/435 [============================>.] - ETA: 0s - loss: 9.7391 - mean_absolute_error: 9.7391\n",
            "Epoch 00022: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7273 - mean_absolute_error: 9.7273\n",
            "Epoch 23/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.7134 - mean_absolute_error: 9.7134\n",
            "Epoch 00023: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7008 - mean_absolute_error: 9.7008\n",
            "Epoch 24/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.8088 - mean_absolute_error: 9.8088\n",
            "Epoch 00024: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7845 - mean_absolute_error: 9.7845\n",
            "Epoch 25/100\n",
            "427/435 [============================>.] - ETA: 0s - loss: 9.6839 - mean_absolute_error: 9.6839\n",
            "Epoch 00025: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.6621 - mean_absolute_error: 9.6621\n",
            "Epoch 26/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.6375 - mean_absolute_error: 9.6375\n",
            "Epoch 00026: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.6150 - mean_absolute_error: 9.6150\n",
            "Epoch 27/100\n",
            "427/435 [============================>.] - ETA: 0s - loss: 9.6263 - mean_absolute_error: 9.6263\n",
            "Epoch 00027: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.6048 - mean_absolute_error: 9.6048\n",
            "Epoch 28/100\n",
            "421/435 [============================>.] - ETA: 0s - loss: 9.6960 - mean_absolute_error: 9.6960\n",
            "Epoch 00028: mean_absolute_error did not improve from 9.58843\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7213 - mean_absolute_error: 9.7213\n",
            "Epoch 29/100\n",
            "426/435 [============================>.] - ETA: 0s - loss: 9.4355 - mean_absolute_error: 9.4355\n",
            "Epoch 00029: mean_absolute_error improved from 9.58843 to 9.42736, saving model to weights.29-9.43.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4274 - mean_absolute_error: 9.4274\n",
            "Epoch 30/100\n",
            "416/435 [===========================>..] - ETA: 0s - loss: 9.3948 - mean_absolute_error: 9.3948\n",
            "Epoch 00030: mean_absolute_error improved from 9.42736 to 9.40056, saving model to weights.30-9.40.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4006 - mean_absolute_error: 9.4006\n",
            "Epoch 31/100\n",
            "433/435 [============================>.] - ETA: 0s - loss: 9.4962 - mean_absolute_error: 9.4962\n",
            "Epoch 00031: mean_absolute_error did not improve from 9.40056\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.5027 - mean_absolute_error: 9.5027\n",
            "Epoch 32/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.4967 - mean_absolute_error: 9.4967\n",
            "Epoch 00032: mean_absolute_error did not improve from 9.40056\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4648 - mean_absolute_error: 9.4648\n",
            "Epoch 33/100\n",
            "432/435 [============================>.] - ETA: 0s - loss: 9.4985 - mean_absolute_error: 9.4985\n",
            "Epoch 00033: mean_absolute_error did not improve from 9.40056\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4924 - mean_absolute_error: 9.4924\n",
            "Epoch 34/100\n",
            "423/435 [============================>.] - ETA: 0s - loss: 9.7340 - mean_absolute_error: 9.7340\n",
            "Epoch 00034: mean_absolute_error did not improve from 9.40056\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.7243 - mean_absolute_error: 9.7243\n",
            "Epoch 35/100\n",
            "427/435 [============================>.] - ETA: 0s - loss: 9.2391 - mean_absolute_error: 9.2391\n",
            "Epoch 00035: mean_absolute_error improved from 9.40056 to 9.25280, saving model to weights.35-9.25.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2528 - mean_absolute_error: 9.2528\n",
            "Epoch 36/100\n",
            "435/435 [==============================] - ETA: 0s - loss: 9.4560 - mean_absolute_error: 9.4560\n",
            "Epoch 00036: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4560 - mean_absolute_error: 9.4560\n",
            "Epoch 37/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.3605 - mean_absolute_error: 9.3605\n",
            "Epoch 00037: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4049 - mean_absolute_error: 9.4049\n",
            "Epoch 38/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.4962 - mean_absolute_error: 9.4962\n",
            "Epoch 00038: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4923 - mean_absolute_error: 9.4923\n",
            "Epoch 39/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.3713 - mean_absolute_error: 9.3713\n",
            "Epoch 00039: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3567 - mean_absolute_error: 9.3567\n",
            "Epoch 40/100\n",
            "423/435 [============================>.] - ETA: 0s - loss: 9.4402 - mean_absolute_error: 9.4402\n",
            "Epoch 00040: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4586 - mean_absolute_error: 9.4586\n",
            "Epoch 41/100\n",
            "420/435 [===========================>..] - ETA: 0s - loss: 9.3394 - mean_absolute_error: 9.3394\n",
            "Epoch 00041: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3619 - mean_absolute_error: 9.3619\n",
            "Epoch 42/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.3371 - mean_absolute_error: 9.3371\n",
            "Epoch 00042: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3425 - mean_absolute_error: 9.3425\n",
            "Epoch 43/100\n",
            "418/435 [===========================>..] - ETA: 0s - loss: 9.5802 - mean_absolute_error: 9.5802\n",
            "Epoch 00043: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.5969 - mean_absolute_error: 9.5969\n",
            "Epoch 44/100\n",
            "414/435 [===========================>..] - ETA: 0s - loss: 9.2807 - mean_absolute_error: 9.2807\n",
            "Epoch 00044: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2917 - mean_absolute_error: 9.2917\n",
            "Epoch 45/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.3114 - mean_absolute_error: 9.3114\n",
            "Epoch 00045: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2930 - mean_absolute_error: 9.2930\n",
            "Epoch 46/100\n",
            "426/435 [============================>.] - ETA: 0s - loss: 9.2910 - mean_absolute_error: 9.2910\n",
            "Epoch 00046: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2800 - mean_absolute_error: 9.2800\n",
            "Epoch 47/100\n",
            "429/435 [============================>.] - ETA: 0s - loss: 9.4446 - mean_absolute_error: 9.4446\n",
            "Epoch 00047: mean_absolute_error did not improve from 9.25280\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4533 - mean_absolute_error: 9.4533\n",
            "Epoch 48/100\n",
            "407/435 [===========================>..] - ETA: 0s - loss: 9.1810 - mean_absolute_error: 9.1810\n",
            "Epoch 00048: mean_absolute_error improved from 9.25280 to 9.19254, saving model to weights.48-9.19.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1925 - mean_absolute_error: 9.1925\n",
            "Epoch 49/100\n",
            "421/435 [============================>.] - ETA: 0s - loss: 9.4570 - mean_absolute_error: 9.4570\n",
            "Epoch 00049: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4895 - mean_absolute_error: 9.4895\n",
            "Epoch 50/100\n",
            "412/435 [===========================>..] - ETA: 0s - loss: 9.3041 - mean_absolute_error: 9.3041\n",
            "Epoch 00050: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3017 - mean_absolute_error: 9.3017\n",
            "Epoch 51/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.4428 - mean_absolute_error: 9.4428\n",
            "Epoch 00051: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4309 - mean_absolute_error: 9.4309\n",
            "Epoch 52/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.3099 - mean_absolute_error: 9.3099\n",
            "Epoch 00052: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3001 - mean_absolute_error: 9.3001\n",
            "Epoch 53/100\n",
            "414/435 [===========================>..] - ETA: 0s - loss: 9.3685 - mean_absolute_error: 9.3685\n",
            "Epoch 00053: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4061 - mean_absolute_error: 9.4061\n",
            "Epoch 54/100\n",
            "416/435 [===========================>..] - ETA: 0s - loss: 9.2148 - mean_absolute_error: 9.2148\n",
            "Epoch 00054: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2645 - mean_absolute_error: 9.2645\n",
            "Epoch 55/100\n",
            "416/435 [===========================>..] - ETA: 0s - loss: 9.3111 - mean_absolute_error: 9.3111\n",
            "Epoch 00055: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3215 - mean_absolute_error: 9.3215\n",
            "Epoch 56/100\n",
            "420/435 [===========================>..] - ETA: 0s - loss: 9.2564 - mean_absolute_error: 9.2564\n",
            "Epoch 00056: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2969 - mean_absolute_error: 9.2969\n",
            "Epoch 57/100\n",
            "411/435 [===========================>..] - ETA: 0s - loss: 9.4305 - mean_absolute_error: 9.4305\n",
            "Epoch 00057: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4295 - mean_absolute_error: 9.4295\n",
            "Epoch 58/100\n",
            "410/435 [===========================>..] - ETA: 0s - loss: 9.4163 - mean_absolute_error: 9.4163\n",
            "Epoch 00058: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3859 - mean_absolute_error: 9.3859\n",
            "Epoch 59/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.3232 - mean_absolute_error: 9.3232\n",
            "Epoch 00059: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3278 - mean_absolute_error: 9.3278\n",
            "Epoch 60/100\n",
            "418/435 [===========================>..] - ETA: 0s - loss: 9.3460 - mean_absolute_error: 9.3460\n",
            "Epoch 00060: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3339 - mean_absolute_error: 9.3339\n",
            "Epoch 61/100\n",
            "420/435 [===========================>..] - ETA: 0s - loss: 9.3138 - mean_absolute_error: 9.3138\n",
            "Epoch 00061: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2910 - mean_absolute_error: 9.2910\n",
            "Epoch 62/100\n",
            "427/435 [============================>.] - ETA: 0s - loss: 9.2851 - mean_absolute_error: 9.2851\n",
            "Epoch 00062: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2916 - mean_absolute_error: 9.2916\n",
            "Epoch 63/100\n",
            "419/435 [===========================>..] - ETA: 0s - loss: 9.2914 - mean_absolute_error: 9.2914\n",
            "Epoch 00063: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2984 - mean_absolute_error: 9.2984\n",
            "Epoch 64/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.3960 - mean_absolute_error: 9.3960\n",
            "Epoch 00064: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3780 - mean_absolute_error: 9.3780\n",
            "Epoch 65/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.2606 - mean_absolute_error: 9.2606\n",
            "Epoch 00065: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2744 - mean_absolute_error: 9.2744\n",
            "Epoch 66/100\n",
            "434/435 [============================>.] - ETA: 0s - loss: 9.3512 - mean_absolute_error: 9.3512\n",
            "Epoch 00066: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3552 - mean_absolute_error: 9.3552\n",
            "Epoch 67/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.3247 - mean_absolute_error: 9.3247\n",
            "Epoch 00067: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3255 - mean_absolute_error: 9.3255\n",
            "Epoch 68/100\n",
            "423/435 [============================>.] - ETA: 0s - loss: 9.3992 - mean_absolute_error: 9.3992\n",
            "Epoch 00068: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3967 - mean_absolute_error: 9.3967\n",
            "Epoch 69/100\n",
            "408/435 [===========================>..] - ETA: 0s - loss: 9.4200 - mean_absolute_error: 9.4200\n",
            "Epoch 00069: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4464 - mean_absolute_error: 9.4464\n",
            "Epoch 70/100\n",
            "421/435 [============================>.] - ETA: 0s - loss: 9.1509 - mean_absolute_error: 9.1509\n",
            "Epoch 00070: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2005 - mean_absolute_error: 9.2005\n",
            "Epoch 71/100\n",
            "428/435 [============================>.] - ETA: 0s - loss: 9.3278 - mean_absolute_error: 9.3278\n",
            "Epoch 00071: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3060 - mean_absolute_error: 9.3060\n",
            "Epoch 72/100\n",
            "419/435 [===========================>..] - ETA: 0s - loss: 9.3239 - mean_absolute_error: 9.3239\n",
            "Epoch 00072: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2960 - mean_absolute_error: 9.2960\n",
            "Epoch 73/100\n",
            "428/435 [============================>.] - ETA: 0s - loss: 9.2013 - mean_absolute_error: 9.2013\n",
            "Epoch 00073: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2033 - mean_absolute_error: 9.2033\n",
            "Epoch 74/100\n",
            "430/435 [============================>.] - ETA: 0s - loss: 9.3186 - mean_absolute_error: 9.3186\n",
            "Epoch 00074: mean_absolute_error did not improve from 9.19254\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3002 - mean_absolute_error: 9.3002\n",
            "Epoch 75/100\n",
            "414/435 [===========================>..] - ETA: 0s - loss: 9.1648 - mean_absolute_error: 9.1648\n",
            "Epoch 00075: mean_absolute_error improved from 9.19254 to 9.18554, saving model to weights.75-9.19.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1855 - mean_absolute_error: 9.1855\n",
            "Epoch 76/100\n",
            "419/435 [===========================>..] - ETA: 0s - loss: 9.3106 - mean_absolute_error: 9.3106\n",
            "Epoch 00076: mean_absolute_error did not improve from 9.18554\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2878 - mean_absolute_error: 9.2878\n",
            "Epoch 77/100\n",
            "418/435 [===========================>..] - ETA: 0s - loss: 9.2243 - mean_absolute_error: 9.2243\n",
            "Epoch 00077: mean_absolute_error did not improve from 9.18554\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2131 - mean_absolute_error: 9.2131\n",
            "Epoch 78/100\n",
            "429/435 [============================>.] - ETA: 0s - loss: 9.2237 - mean_absolute_error: 9.2237\n",
            "Epoch 00078: mean_absolute_error did not improve from 9.18554\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2417 - mean_absolute_error: 9.2417\n",
            "Epoch 79/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.1333 - mean_absolute_error: 9.1333\n",
            "Epoch 00079: mean_absolute_error improved from 9.18554 to 9.13994, saving model to weights.79-9.14.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1399 - mean_absolute_error: 9.1399\n",
            "Epoch 80/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.3057 - mean_absolute_error: 9.3057\n",
            "Epoch 00080: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3237 - mean_absolute_error: 9.3237\n",
            "Epoch 81/100\n",
            "412/435 [===========================>..] - ETA: 0s - loss: 9.2490 - mean_absolute_error: 9.2490\n",
            "Epoch 00081: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2754 - mean_absolute_error: 9.2754\n",
            "Epoch 82/100\n",
            "426/435 [============================>.] - ETA: 0s - loss: 9.3421 - mean_absolute_error: 9.3421\n",
            "Epoch 00082: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3444 - mean_absolute_error: 9.3444\n",
            "Epoch 83/100\n",
            "423/435 [============================>.] - ETA: 0s - loss: 9.3869 - mean_absolute_error: 9.3869\n",
            "Epoch 00083: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4298 - mean_absolute_error: 9.4298\n",
            "Epoch 84/100\n",
            "414/435 [===========================>..] - ETA: 0s - loss: 9.2707 - mean_absolute_error: 9.2707\n",
            "Epoch 00084: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2536 - mean_absolute_error: 9.2536\n",
            "Epoch 85/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.2655 - mean_absolute_error: 9.2655\n",
            "Epoch 00085: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2424 - mean_absolute_error: 9.2424\n",
            "Epoch 86/100\n",
            "423/435 [============================>.] - ETA: 0s - loss: 9.1886 - mean_absolute_error: 9.1886\n",
            "Epoch 00086: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1540 - mean_absolute_error: 9.1540\n",
            "Epoch 87/100\n",
            "424/435 [============================>.] - ETA: 0s - loss: 9.4537 - mean_absolute_error: 9.4537\n",
            "Epoch 00087: mean_absolute_error did not improve from 9.13994\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4201 - mean_absolute_error: 9.4201\n",
            "Epoch 88/100\n",
            "411/435 [===========================>..] - ETA: 0s - loss: 9.0946 - mean_absolute_error: 9.0946\n",
            "Epoch 00088: mean_absolute_error improved from 9.13994 to 9.06616, saving model to weights.88-9.07.hdf5\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.0662 - mean_absolute_error: 9.0662\n",
            "Epoch 89/100\n",
            "427/435 [============================>.] - ETA: 0s - loss: 9.1909 - mean_absolute_error: 9.1909\n",
            "Epoch 00089: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1822 - mean_absolute_error: 9.1822\n",
            "Epoch 90/100\n",
            "426/435 [============================>.] - ETA: 0s - loss: 9.2225 - mean_absolute_error: 9.2225\n",
            "Epoch 00090: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2232 - mean_absolute_error: 9.2232\n",
            "Epoch 91/100\n",
            "425/435 [============================>.] - ETA: 0s - loss: 9.2972 - mean_absolute_error: 9.2972\n",
            "Epoch 00091: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.3068 - mean_absolute_error: 9.3068\n",
            "Epoch 92/100\n",
            "426/435 [============================>.] - ETA: 0s - loss: 9.4365 - mean_absolute_error: 9.4365\n",
            "Epoch 00092: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.4668 - mean_absolute_error: 9.4668\n",
            "Epoch 93/100\n",
            "419/435 [===========================>..] - ETA: 0s - loss: 9.1432 - mean_absolute_error: 9.1432\n",
            "Epoch 00093: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1703 - mean_absolute_error: 9.1703\n",
            "Epoch 94/100\n",
            "409/435 [===========================>..] - ETA: 0s - loss: 9.2232 - mean_absolute_error: 9.2232\n",
            "Epoch 00094: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2175 - mean_absolute_error: 9.2175\n",
            "Epoch 95/100\n",
            "409/435 [===========================>..] - ETA: 0s - loss: 9.2135 - mean_absolute_error: 9.2135\n",
            "Epoch 00095: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2094 - mean_absolute_error: 9.2094\n",
            "Epoch 96/100\n",
            "426/435 [============================>.] - ETA: 0s - loss: 9.2956 - mean_absolute_error: 9.2956\n",
            "Epoch 00096: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.2824 - mean_absolute_error: 9.2824\n",
            "Epoch 97/100\n",
            "417/435 [===========================>..] - ETA: 0s - loss: 9.0942 - mean_absolute_error: 9.0942\n",
            "Epoch 00097: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1052 - mean_absolute_error: 9.1052\n",
            "Epoch 98/100\n",
            "422/435 [============================>.] - ETA: 0s - loss: 9.1228 - mean_absolute_error: 9.1228\n",
            "Epoch 00098: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1788 - mean_absolute_error: 9.1788\n",
            "Epoch 99/100\n",
            "421/435 [============================>.] - ETA: 0s - loss: 9.2019 - mean_absolute_error: 9.2019\n",
            "Epoch 00099: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1964 - mean_absolute_error: 9.1964\n",
            "Epoch 100/100\n",
            "419/435 [===========================>..] - ETA: 0s - loss: 9.1289 - mean_absolute_error: 9.1289\n",
            "Epoch 00100: mean_absolute_error did not improve from 9.06616\n",
            "435/435 [==============================] - 1s 2ms/step - loss: 9.1222 - mean_absolute_error: 9.1222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O06q_SOeNcxT"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_new = load_model('/content/weights.88-9.07.hdf5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0d73mbJSkZ7",
        "outputId": "d4c61df6-1ea1-4655-efd6-5e2740659271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 30)                450       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 125)               3875      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 200)               25200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 29,726\n",
            "Trainable params: 29,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my4SZuY6Pedn"
      },
      "source": [
        "y_pred = model_new.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRmMB4SsODAh",
        "outputId": "59e8401d-3980-4d6b-a342-289757dea205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "error = mean_absolute_error(y_test, y_pred)\n",
        "print(error)\n",
        "#The error is 99.18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6435587233311835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wQZTwWWfbdc",
        "outputId": "0d725c21-6d0a-4514-d8f8-c009ec6f764d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "accuracy = r2_score(y_test, y_pred)\n",
        "print('Model accuracy is = {:0.6f}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy is = 0.999576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwLjyoYzYbCR",
        "outputId": "441cc75d-a783-4dc0-eb8b-08cd7c29e679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "#The shape of weights for the selected model\n",
        "model_4 = load_model('/content/weights.best.hdf5')\n",
        "for layer in model.layers:\n",
        "  if len(layer.weights) > 0:\n",
        "    print(layer.name, layer.weights[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_81 (14, 30)\n",
            "dense_82 (30, 32)\n",
            "dense_83 (32, 32)\n",
            "dense_84 (32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBJSKmdXY5cc"
      },
      "source": [
        "\n",
        "At each epoch, the model completes training on all the observations of the train set. Therefore, at 4th epoch, model has gone through the train set for 3 times. In order to perform backpropagation, forward propagation should be completed. The values from the last layer of the nueral networks got from the forward propagation are considered. dJ/dw1 (for each weights of input layer i.e. 14 cols) and dJ/db where J is the cost function. These gradients could be used in the adam optimizers to improve the weights and biases where the cost function is the minimum. The following cost function shows the weight matrices for layer3, layer2 and layer1 of the model. The weights are updated such that the cost function is the lowest.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRA3FkDEW2LE",
        "outputId": "dff99dfd-7cb0-4347-9679-266cc61527f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#The weights in layer 3 would be zero since it consists of the outputs\n",
        "model_4_3 = load_model('/content/weights.04-10.05.hdf5')\n",
        "weight_layer_4_3=model_4_3.layers[3].get_weights()\n",
        "print(weight_layer_4_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkbAmb8DklWl",
        "outputId": "8578f039-00a0-44c4-dd34-016e30f37952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "#Weight Matrix of 2nd layer of epoch 4\n",
        "weight_layer_4_2=model_4_1.layers[2].get_weights()\n",
        "print(weight_layer_4_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[-0.00458941,  0.04921785, -0.08894711, ..., -0.04426719,\n",
            "         0.05454879,  0.08504193],\n",
            "       [-0.06793217,  0.17300902, -0.07112951, ..., -0.1079075 ,\n",
            "        -0.06335767,  0.03065375],\n",
            "       [ 0.0791788 , -0.04300268,  0.10687821, ..., -0.06552172,\n",
            "        -0.14840503,  0.16467042],\n",
            "       ...,\n",
            "       [-0.0272062 , -0.04702072,  0.10114998, ..., -0.05975083,\n",
            "         0.05803816, -0.0698769 ],\n",
            "       [-0.00776919, -0.0016284 , -0.15676688, ..., -0.05249582,\n",
            "         0.09171531,  0.09002262],\n",
            "       [-0.02660254, -0.11120652, -0.01088137, ..., -0.05030262,\n",
            "         0.03885168,  0.04014947]], dtype=float32), array([-0.0281083 ,  0.02904174,  0.00230422,  0.02941417,  0.02290462,\n",
            "       -0.02293523, -0.03086608,  0.01144583,  0.03060494,  0.01677356,\n",
            "       -0.02704727,  0.        ,  0.03764931,  0.00875828,  0.0437961 ,\n",
            "       -0.01937194,  0.04052368, -0.0117595 , -0.01157436, -0.0470533 ,\n",
            "        0.03466826,  0.02216711,  0.03011546, -0.02730229, -0.01722995,\n",
            "       -0.01147005,  0.02114981, -0.03099835, -0.01180785, -0.02615125,\n",
            "       -0.02530342, -0.02506916, -0.06239656, -0.00511173,  0.03746255,\n",
            "       -0.01166423, -0.02494145, -0.0449784 , -0.02578956,  0.02350351,\n",
            "        0.06150819, -0.03650838, -0.04784504, -0.05045694,  0.00350687,\n",
            "       -0.03197005,  0.01133979, -0.0352992 , -0.01834992,  0.01634743,\n",
            "        0.05843166,  0.02982653, -0.03032273,  0.06254414,  0.04307821,\n",
            "       -0.0441307 , -0.01232165, -0.01131816, -0.02690906, -0.00209072,\n",
            "        0.02799084,  0.00055444,  0.        , -0.00904012, -0.0375368 ,\n",
            "       -0.0278096 , -0.0382329 , -0.06399272, -0.00545786,  0.02748413,\n",
            "       -0.0253206 , -0.0024031 ,  0.00455068, -0.02011476, -0.02892994,\n",
            "       -0.01620832, -0.02271197, -0.05353571,  0.04779326, -0.02600366,\n",
            "        0.01604206,  0.02127911,  0.02601684, -0.02997951,  0.0242446 ,\n",
            "        0.01521222, -0.01358409, -0.01141861, -0.07526697, -0.02296588,\n",
            "        0.08797559, -0.01514704,  0.01686924, -0.04280706, -0.01431361,\n",
            "       -0.04575454, -0.04352796, -0.00433532, -0.02604484,  0.04528039,\n",
            "        0.00112166,  0.        ,  0.02936695,  0.01908264, -0.01961003,\n",
            "       -0.02259099,  0.00195107, -0.01085832,  0.00362696,  0.06056131,\n",
            "        0.01591278, -0.02829314,  0.02006304,  0.00202394, -0.01838987,\n",
            "       -0.02848833,  0.00521142, -0.03831687, -0.02437991,  0.01040827,\n",
            "       -0.02551316, -0.05607808,  0.00198539, -0.0316162 ,  0.00367425,\n",
            "       -0.01350771,  0.05594542, -0.03147445, -0.03622274, -0.0102306 ,\n",
            "        0.02593978, -0.01598679,  0.01879495, -0.0401947 ,  0.02257756,\n",
            "       -0.01565436, -0.02869384,  0.09443573, -0.02684502, -0.015436  ,\n",
            "       -0.03592689, -0.0331009 ,  0.02742971,  0.01288744, -0.04289482,\n",
            "       -0.05366718,  0.05173698, -0.02831554,  0.02099875,  0.03094964,\n",
            "       -0.03375158,  0.03799186,  0.02445419, -0.02363911, -0.02738057,\n",
            "        0.08138835,  0.0520185 ,  0.02181447,  0.01613457, -0.03864172,\n",
            "       -0.02047825,  0.        ,  0.1200882 ,  0.02378521,  0.02087234,\n",
            "       -0.04905302,  0.02283643, -0.06524146,  0.01572396, -0.00212498,\n",
            "        0.04308843,  0.01658479,  0.01041351, -0.03580747,  0.01619419,\n",
            "       -0.02412992,  0.00331936,  0.0204179 , -0.04316526,  0.03017697,\n",
            "        0.0131508 , -0.0100348 ,  0.00184105, -0.01195012, -0.003297  ,\n",
            "        0.01876884, -0.02862535, -0.00264678, -0.05781608,  0.02278575,\n",
            "        0.02291247,  0.0162824 ,  0.03174012,  0.00073627,  0.02540675,\n",
            "       -0.02512046, -0.01219428, -0.02090498, -0.03072303,  0.05325706],\n",
            "      dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6fpVdLJa01D"
      },
      "source": [
        "Now consider two layers: Layer 1 and Layer2 for the best model (88 epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ0CT5Pdq1Ve"
      },
      "source": [
        "In Layer 1, the input weights from 0th layer enters and is subjected to the ReLu activation function that causes non-linearity in the corresponding output of layer 1. The weight matrix for layer 1 is shown below. Since layer 1 consists of 125 hidden units, the 125 activation functions are applied to different inputs in order to obtain the output Z1,...,Z125 where Z is the output result from activation function (ReLu in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJawaSO9sbmy"
      },
      "source": [
        "layer_model = load_model('/content/weights.88-9.07.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzljqQNuW8xw",
        "outputId": "a0f07682-3368-4b7f-b81a-86c93a3077a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "#The dimensions of this weight matrix would W[n0, n1] where n is the no. of hidden units. \n",
        "#Therefore, W is of shape [30, 125]\n",
        "weight_layer1=layer_model.layers[1].get_weights()\n",
        "weight_layer1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.00355187, -0.21751715, -0.10569739, ..., -0.00188616,\n",
              "         -0.0109664 ,  0.18243833],\n",
              "        [ 0.01861395, -0.05245482, -0.00219852, ...,  0.01996835,\n",
              "         -0.04726018, -0.27175313],\n",
              "        [ 0.07646588,  0.13112396, -0.07909629, ...,  0.14895868,\n",
              "          0.16435474,  0.04438773],\n",
              "        ...,\n",
              "        [-0.02012443, -0.163281  ,  0.13718003, ..., -0.14855516,\n",
              "          0.07398589, -0.0188133 ],\n",
              "        [-0.09043436,  0.00047712, -0.12893668, ..., -0.16364358,\n",
              "         -0.19972505, -0.209863  ],\n",
              "        [-0.08225781, -0.15726183, -0.0965673 , ..., -0.19278766,\n",
              "         -0.09948368,  0.03678462]], dtype=float32),\n",
              " array([ 0.2347689 , -0.08649663, -0.11545159, -0.18231101, -0.21604803,\n",
              "        -0.21787594, -0.10799897, -0.28542998, -0.24323739,  0.01999495,\n",
              "        -0.18727298, -0.11569253,  0.07830626, -0.17924109, -0.23356818,\n",
              "        -0.15116297, -0.13398866, -0.14642449, -0.22420427, -0.27072266,\n",
              "        -0.16865166, -0.05801897, -0.18878292, -0.30473495, -0.10379376,\n",
              "        -0.2537384 ,  0.14993906,  0.2454785 , -0.19849753, -0.16137598,\n",
              "        -0.07411191, -0.24632171, -0.13114865, -0.21527958, -0.11172778,\n",
              "        -0.17518854, -0.12215617,  0.22130747, -0.10453527,  0.10025676,\n",
              "        -0.02832087, -0.20930132, -0.0297956 , -0.17269713, -0.15877815,\n",
              "        -0.01293221, -0.02341864, -0.21012188, -0.16335493, -0.15828726,\n",
              "         0.33258757, -0.16680406, -0.09257863, -0.12907237, -0.19929205,\n",
              "        -0.20155758, -0.22269937, -0.10466027, -0.08541329, -0.03168764,\n",
              "        -0.25111517, -0.23170696, -0.10785227, -0.01164672,  0.        ,\n",
              "        -0.21509622, -0.06233178, -0.06371401, -0.3431866 , -0.11819881,\n",
              "         0.44990414, -0.08365945, -0.21249676, -0.10625994,  0.5117121 ,\n",
              "         0.38575867, -0.04825209, -0.20684505, -0.15059671, -0.16499798,\n",
              "        -0.16236337, -0.14646713, -0.17384021, -0.07421882, -0.03105689,\n",
              "        -0.28242496,  0.02670039, -0.12928599,  0.22099759, -0.11007527,\n",
              "         0.14051355,  0.3584707 , -0.18792966, -0.19271594, -0.01020995,\n",
              "        -0.09482597, -0.14790982, -0.13844267, -0.07305085,  0.24327962,\n",
              "        -0.20766078, -0.10564184, -0.14063886, -0.04863591, -0.1403682 ,\n",
              "        -0.09009191, -0.12876473, -0.1062663 , -0.13272922, -0.13378105,\n",
              "         0.5308407 , -0.12478891, -0.03700316, -0.19442494, -0.21772586,\n",
              "        -0.10528278, -0.38924065, -0.12719835, -0.27262735,  0.0792643 ,\n",
              "        -0.08562404, -0.3178917 , -0.01136099, -0.06880347,  0.39807987],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQnzIZhWa4O6"
      },
      "source": [
        "In Layer 2, the input weights from 1st layer enters and is subjected to the ReLu activation function that causes non-linearity in the corresponding output of layer 2. The weight matrix for layer 2 is shown below. Since layer 1 consists of 30 hidden units, the 30 activation functions are applied to different inputs in order to obtain the output Z200,...,Z200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ol88zDhfVgG",
        "outputId": "67b2bc0a-bc25-4c9b-a9df-944df9fe6688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "weight_layer_2=layer_model.layers[2].get_weights()\n",
        "print(weight_layer_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[-0.06904548, -0.04293536,  0.06275894, ..., -0.04426719,\n",
            "         0.05454879, -0.00467303],\n",
            "       [-0.02284556,  0.16231243, -0.03582188, ..., -0.1079075 ,\n",
            "        -0.06335767, -0.00346581],\n",
            "       [ 0.07445255, -0.04596286,  0.1022029 , ..., -0.06552172,\n",
            "        -0.14840503,  0.14089508],\n",
            "       ...,\n",
            "       [-0.07680734, -0.01629007,  0.15614364, ..., -0.08882368,\n",
            "         0.05803816, -0.0644895 ],\n",
            "       [-0.09181899, -0.0539087 , -0.1941104 , ..., -0.05249582,\n",
            "         0.06950644,  0.05294609],\n",
            "       [ 0.29835275, -0.09052721,  0.30216485, ..., -0.05030262,\n",
            "         0.00829348, -0.16802594]], dtype=float32), array([ 0.20210642, -0.00418124,  0.13864769,  0.01497327,  0.02495383,\n",
            "       -0.07555717, -0.01009439, -0.0310457 ,  0.02063909,  0.01153323,\n",
            "       -0.09370562, -0.06125431, -0.0010783 , -0.06664619, -0.00818328,\n",
            "       -0.11395684, -0.05478109, -0.04326407, -0.02724057, -0.16712552,\n",
            "       -0.00630098, -0.07779337,  0.0303162 , -0.10858808, -0.08742786,\n",
            "        0.02324996,  0.01650179, -0.03788782, -0.11227138,  0.12000798,\n",
            "       -0.06530754, -0.0871195 , -0.0871171 , -0.05688256, -0.03366876,\n",
            "       -0.00980953, -0.02966868, -0.06010719, -0.02819865, -0.03078882,\n",
            "       -0.11014232, -0.12055468, -0.09524   ,  0.20334212, -0.07771373,\n",
            "        0.26775578, -0.02483378, -0.11553843, -0.0515095 ,  0.00694359,\n",
            "       -0.00890811, -0.05561019, -0.06430388,  0.03895688,  0.04003637,\n",
            "       -0.11611221, -0.00215701, -0.02899218, -0.05853326, -0.09077252,\n",
            "       -0.07643896,  0.04218987, -0.03120268, -0.06754989, -0.11045389,\n",
            "       -0.04796356, -0.142573  , -0.07260408, -0.09269267, -0.04337805,\n",
            "       -0.0558489 , -0.05578212, -0.00896404,  0.1200927 , -0.10216806,\n",
            "       -0.08817132,  0.12374138, -0.13809046,  0.01051638, -0.0384215 ,\n",
            "       -0.00147566, -0.01633113,  0.03502066, -0.12784125,  0.02224134,\n",
            "       -0.04665859, -0.08819436, -0.09718963, -0.12563019, -0.0689612 ,\n",
            "        0.01082333,  0.18113726, -0.03862756, -0.12469979, -0.04503794,\n",
            "       -0.09929834, -0.12282083,  0.0248716 , -0.03430196,  0.01502186,\n",
            "       -0.08756274, -0.06117039, -0.04502776, -0.01125772, -0.08171694,\n",
            "       -0.14092557, -0.11022864, -0.0722112 , -0.00592301,  0.01243884,\n",
            "       -0.01389824, -0.1276719 , -0.06863067, -0.02383289, -0.02455422,\n",
            "        0.15491037,  0.01726232,  0.21663758, -0.07800754,  0.05758251,\n",
            "       -0.05929437, -0.13474691, -0.04319134, -0.10553855, -0.04917153,\n",
            "        0.14340869, -0.07549813, -0.0544708 ,  0.33519244, -0.08621406,\n",
            "       -0.02534652, -0.1048834 , -0.03419005, -0.06932612,  0.00085063,\n",
            "       -0.04722754, -0.08859489, -0.0007424 , -0.03781068,  0.19120558,\n",
            "       -0.12193789, -0.03214629,  0.0191013 ,  0.01401075, -0.03242404,\n",
            "       -0.03978908,  0.03980775, -0.09172505, -0.04702534, -0.00203801,\n",
            "       -0.06289485, -0.09478325,  0.01249086, -0.07977267, -0.06601399,\n",
            "        0.02675782,  0.04188358,  0.0546529 , -0.0420819 , -0.05961548,\n",
            "        0.19516304, -0.03567429,  0.03148271, -0.01694744,  0.03748331,\n",
            "       -0.04927753,  0.14537308, -0.11005161,  0.01388911,  0.20245618,\n",
            "        0.03244012,  0.00197049, -0.00840359, -0.13012241,  0.03690769,\n",
            "       -0.08399349,  0.041926  , -0.10149103, -0.1440596 , -0.02933284,\n",
            "       -0.01600063, -0.02940051, -0.02686347,  0.18110302, -0.08825242,\n",
            "       -0.05294125, -0.04342947, -0.05102217, -0.10649719,  0.00859454,\n",
            "       -0.05090155, -0.02577866, -0.00529119, -0.03405868, -0.02290365,\n",
            "       -0.05686238, -0.03560498, -0.05974599, -0.09175255,  0.03500702],\n",
            "      dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot_kRUJpsmqE"
      },
      "source": [
        "The third layer is the output layer that consists of predictions and therefore lacks weight matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_dehiXVn_Ia",
        "outputId": "20ed9e5d-aee2-4f66-ae2a-81928f7eb514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weight_layer_3=layer_model.layers[3].get_weights()\n",
        "print(weight_layer_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}